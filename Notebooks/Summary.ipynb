{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a summary statement that highlights the key processes and findings from this notebook. This should include information such as the original number of rows in the data, whether our own resort was actually present etc. What columns, if any, have been removed? Any rows? Summarise the reasons why. Were any other issues found? What remedial actions did you take? State where you are in the project. Can you confirm what the target feature is for your desire to predict ticket price? How many rows were left in the data? Hint: this is a great opportunity to reread your notebook, check all cells have been executed in order and from a \"blank slate\" (restarting the kernel will do this), and that your workflow makes sense and follows a logical pattern. As you do this you can pull out salient information for inclusion in this summary. Thus, this section will provide an important overview of \"what\" and \"why\" without having to dive into the \"how\" or any unproductive or inconclusive steps along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original data information\n",
    "\n",
    "- The original dataset cointained 330 rows and 27 columns including the variables:\n",
    "      ['Name','Region', 'state', 'summit_elev', 'vertical_drop', 'base_elev',\n",
    "       'trams', 'fastEight', 'fastSixes', 'fastQuads', 'quad', 'triple',\n",
    "       'double', 'surface', 'total_chairs', 'Runs', 'TerrainParks',\n",
    "       'LongestRun_mi', 'SkiableTerrain_ac', 'Snow Making_ac',\n",
    "       'daysOpenLastYear', 'yearsOpen', 'averageSnowfall', 'AdultWeekday',\n",
    "       'AdultWeekend', 'projectedDaysOpen', 'NightSkiing_ac']. \n",
    "   With a total of 636 missing values. \n",
    "      \n",
    "- Our resort Big Mountain was present and was not missing any variables. \n",
    "\n",
    "- The data was organized by State and Region. Most State names were equal to the Region names (297) while some (33) were different. \n",
    "\n",
    "- Plotting a histogram of each variable revealed potential outliers and variables without an even distribution that would not be useful in out model      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.hist(figsize=(15,10))\n",
    "plt.subplots_adjust(hspace=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'SkiableTerrain_ac'\n",
    "* 'Snow Making_ac'\n",
    "* 'fastEight'\n",
    "* 'fastSixes' \n",
    "* 'trams' \n",
    "* 'yearsOpen'\n",
    "* 'fastQuads'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After careful examination, we were able to take care of the outliers in `yearsOpen` and `SkiableTerrain_ac`. We dropped `fastEight` as half its values were missing. We kept `fastSixes`, `trams` and `fastQuads` for now.\n",
    "\n",
    "- All observations that were missing both target variables were dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data2.hist(figsize=(15, 10))\n",
    "plt.subplots_adjust(hspace=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the variable's distributions are lookign much better. \n",
    "\n",
    "A dataset of Population and area data for the US (obtained from wikipedia.com) was merged with the total sum of `SkiableTerrain_ac`, `daysOpenLastYear`, `TerrainParks`, `NightSkiing_ac` and `resort_per_state` to evaluate any possible relations with the state population and area.\n",
    "\n",
    "- Upon closer examination of our tagert state (Montana), we observed that `AdultWeekend` and `AdultWeekday` have the same value across all resorts. Therefore, we dropped `AdultWeekday`, as it had the most missing values, and dropped all observations with missing values in `AdultWeekend`. \n",
    "\n",
    "- We ended up with a final dataset of 277 rows and 25 variables, as well as 299 missing values.\n",
    "\n",
    "- At this point, we can not confirm what the predictor variables are, but we can confirm that `AdultWeekend` is our desired target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis Summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a summary of the exploratory data analysis above. What numerical or categorical features were in the data? Was there any pattern suggested of a relationship between state and ticket price? What did this lead us to decide regarding which features to use in subsequent modeling? What aspects of the data (e.g. relationships between features) should you remain wary of when you come to perform feature selection for modeling? Two key points that must be addressed are the choice of target feature for your modelling and how, if at all, you're going to handle the states labels in the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We explored the ratio of resort to state population and state area. This revealed some strong correlations as the states expected to lead in each variable were not present in the density top resorts. \n",
    "\n",
    "- To do away with this strong correlations, we applied PCA. In order to do so, we first scaled the data, fitted the PCA transformation and applied the trasnformation to create derived features. \n",
    "\n",
    "- We created a data frame with the two principal components, the average ticket price and created a categorical variable that categorized each observation in a quartile range.\n",
    "\n",
    "- A scatter plot of this data frame revealed no patterns concerning the ticket price. This makes deciding to use the state labels a little unclear. On one hand, the state label seems revelant when it comes to the population (potential customers) and the ratio of resorts to the state area (competition). On the other hand, state labels showed no patterns when evaluated against ticket prices. I believe we should evaluate variables that show strong correlations with the target variable with and without the state labels and see what differences we can encounter.\n",
    "\n",
    "- We converted the states' quantifiable variables into ratios for each observation (e.g `NightSkiing_ac`/`state_total_nightskiing_ac`)\n",
    "\n",
    "- A correlation heatmap revealed some strong correlations between `AdultWeekend` and `fastQuads`, `Runs`, `Snow Making_ac`, `resort_night_skiing_state_ratio`, `vertical_drop` and `total_chairs`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing & Training Summary\n",
    "\n",
    "Write a summary of the work in this notebook. Capture the fact that you gained a baseline idea of performance by simply taking the average price and how well that did. Then highlight that you built a linear model and the features that found. Comment on the estimate of its performance from cross-validation and whether its performance on the test split was consistent with this estimate. Also highlight that a random forest regressor was tried, what preprocessing steps were found to be best, and again what its estimated performance via cross-validation was and whether its performance on the test set was consistent with that. State which model you have decided to use going forwards and why. This summary should provide a quick overview for someone wanting to know quickly why the given model was chosen for the next part of the business problem to help guide important business decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As our first step, we divided the data into training and test data.\n",
    "- Second, we used the mean value as a baseline. As expected, its performance was very poor, with ùëÖ2 = -0.00312 when compared against the test values. This translated to the model being off by an average of `$19.`\n",
    "- Once our baseline was covered, we imputed missing values with both the mean and median, scaled the the predictors, and tried a linear regression model, this showed no significant difference between the two imputing alternatives.\n",
    "- After, we applied the same test using the built-in pipelines sklearn offers. We had the exact same values in both methods.\n",
    "- We proceeded to refine the linear model using SelectKBest to avoid overfitting the models with all the predictros. We performed a cross validation to avoid tuning the model to an arbitrary test set. \n",
    "- We also applied a grid search to automate the process of selecting the best k for SelectKBest. This return k = 8 as the best number of predictors: `vertical_drop`, `Snow Making_ac`, `total_chairs`, `fastQuads`, `Runs`, `LongestRun_mi`, `trams`, and `SkiableTerrain_ac`.\n",
    "- We compared the linear regression model to a random forest model. We used the same grid search and got `fastQuads`, `Runs`, `Snow Making_ac`, `vertical_drop` as the best predictors for the model.\n",
    "- We cross-validated both models using the best estimators and random forest was the best model with a MAE of `$9.5`, almost `$1` more accurate than the linear model.\n",
    "- To finalize, we made sure our data set size was good enough for our prediction by using `learning_curve`. This determined a data set of around 40 to 50 observation was good enough to create a predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Summary\n",
    "\n",
    "Write a summary of the results of modeling these scenarios. Start by starting the current position; how much does Big Mountain currently charge? What does your modelling suggest for a ticket price that could be supported in the marketplace by Big Mountain's facilities? How would you approach suggesting such a change to the business leadership? Discuss the additional operating cost of the new chair lift per ticket (on the basis of each visitor on average buying 5 day tickets) in the context of raising prices to cover this. For future improvements, state which, if any, of the modeled scenarios you'd recommend for further consideration. Suggest how the business might test, and progress, with any run closures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Right now, Big Mountain is charging `$81` per ticket, as opposed to the `$95.87` (`+- $10.39`) suggested by the model.\n",
    "- Based in our analysis, the ski resort marketplace seems to value `vertical_drop`, `Snow Making_ac`, `total_chairs`, `fastQuads`, `Runs`, `LongestRun_mi`, `trams`, and `SkiableTerrain_ac` as the amenities that determine the ticket price. Big Mountain on the higher end when comparing these amenities to the rest of the resorts in the country. at `$81` a ticket, it is one of the most expensive resorts in the state of Montana, however, our analysis revealed that states do not play a roll in the ticket prices.\n",
    "- The new lift costs `$1,540,000` to operate, that equates to `$0.88` per ticket (on the basis of each visitor on average buying 5 day tickets). The propsed new price strategy will easily cover this increase in operational cost.\n",
    "- If Big Mountain decided to close the least used runs (Scenario 1), closing 3 to 5 runs will have the same impact in ticket price. Therefore, closing 5 runs will lead to more savings. This is the same case for closing 6 to 8 runs, however, the ticket price will be affected more. Scenario 2 & 3 will yield the same results, therefore, Scenario 2 will be the best option since it will cost less to implement. In conclusion, a combination of Scenario 1 & 2 will probably have the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Work\n",
    "\n",
    "What next? Highlight any deficiencies in the data that hampered or limited this work. The only price data in our dataset were ticket prices. You were provided with information about the additional operating cost of the new chair lift, but what other cost information would be useful? Big Mountain was already fairly high on some of the league charts of facilities offered, but why was its modeled price so much higher than its current price? Would this mismatch come as a surprise to the business executives? How would you find out? Assuming the business leaders felt this model was useful, how would the business make use of it? Would you expect them to come to you every time they wanted to test a new combination of parameters in a scenario? We hope you would have better things to do, so how might this model be made available for business analysts to use and explore?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Understanding how the ticket price from the other resort was generated, what was taken into account, what influenced the decision, etc, would help us to make a better market analysis and be more condifent in our model.\n",
    "- Cost information regarding the additions proposed in Scenario 2 would have been useful to make a decision in whether or not this will increase revenue. \n",
    "- The modeled price is higher because the current price was calculated from the average price across the other resorts. This did not take into consideration the quality of each resort like the model does. From the data provided, Big Mountain is a high end resort and a higher price should not come as a surpise. \n",
    "- In the future, if Big Mountain decided to make more changes and needed to reassess the ticket price, the future business analyst will be able to use `ski_resort_pricing_model.pkl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
